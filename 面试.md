# 面试
## a. DL
1. attention
2. 交叉熵求导
3. rnn反向传播
4. 优化算法
5. 损失函数
6. lstm结构，相对rnn梯度消失问题解决，gru
7. 梯度消失，爆炸，(修剪，relu，bn, resnet )
8. 正则化，ln，bn，dropout
9. seq2seq，attention
10. word2vec,，负采样，分层softmax，效果评价
11. bleu
12. TF-IDF, LDA
13. attention 不同机制
## b. ML
1. 集成方法：GDBT，xgboost（参数有哪些，如何调整）
2. 决策树，ID3-4, C4.5, cart，GD；随机森林
3. HMM, CRF，维特比算法
4. SVM, kernal, Hingle loss，核函数操作
5. k-means ++ ,kernal kmeans, pca,kpca
6. lasso 回归之前一定要做标准化
7. 线性回归，如果两个变量之间存在共线性，做中心化，看是否共线性缓解，否则删除一个。
8. 查准率，查全率
9. 生成模型
10. 特征选择方法
11. 最大似然估计
12. RBM 受限玻尔兹曼机
13. 霍夫检测直线，圆形，矩形
14. 协同过滤
15. 正负样本不均衡：重采样、欠采样、调整权重、合成样本等
16. VC维
17. EM算法
## c. 数据结构
1. hash表
2. 前中后序遍历
3. 线性表不同结构的优缺点（链式，索引，散列，顺序）
4. 排序算法（快速排序的特点，每n趟排序后至少有n个元素已经在其正确的位置上）
5. 进制数
6. 一亿个数找出top n
## d. 统计
1. 概率分布定义
2. 高斯混合分布
3. 各种距离
4. 熵计算
5. 相关系数，独立性，相关性
6. 大数定理，切比雪夫定理，中心极限定理
7. 广义逆矩阵
## e. 凸优化
1. 优化方法
2. KKT，对偶
## f. python
1. lamda表达式，列表表达式
